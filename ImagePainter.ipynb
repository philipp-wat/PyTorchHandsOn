{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task and Setup\n",
    "\n",
    "Mini-project in PyTorch for getting expereience.\n",
    "\n",
    "Loads images, blacks a specific part of them, trains a model to predict the blacked part.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import mkdir\n",
    "from zipfile import ZipFile\n",
    "import urllib\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "from os.path import exists, join\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from copy import copy\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from statistics import mean \n",
    "import tqdm.notebook as tq\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###--- Get Data---#\n",
    "\n",
    "working_path = os.getcwd()\n",
    "print(\"Start path:\", working_path)\n",
    "\n",
    "dataURL = \"https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB-Training_fixed.zip\"\n",
    "fileName = \"GTSRB-Training_fixed.zip\"\n",
    "path = \"./pytorch_project\"\n",
    "path_data = \"./data\"\n",
    "millis = int(round(time.time() * 1000))\n",
    "\n",
    "# Create folder in current path\n",
    "# Checks wethere the folder exisits or not, raises exception if something goes wrong\n",
    "# Checks if the path name is part of the actual path and if path exists in general\n",
    "try:\n",
    "    if os.path.exists(path) == False and str(path)[2:] not in (working_path):\n",
    "        os.mkdir(path)\n",
    "        print (\"Successfully created %s \" % path)\n",
    "    else: \n",
    "        print (\"The directory %s already exists\" % path)\n",
    "except (OSError, Exception):\n",
    "    print (\"Creation of the directory %s failed\" % path)\n",
    "\n",
    "    \n",
    "# Switches in the correct working dir    \n",
    "if str(path)[2:] not in (working_path):\n",
    "    os.chdir(path)\n",
    "working_path = os.getcwd()\n",
    "print(f\"Working now in: {working_path}\")\n",
    "\n",
    "# Init tensorbaord writer\n",
    "writer = SummaryWriter(f\"runs/write_{millis}\")\n",
    "\n",
    "# Download and unzip the data\n",
    "try:\n",
    "    if os.path.exists(path_data) == False:\n",
    "        # Copy a network object to a local file\n",
    "        print (\"Start download to:\", fileName)\n",
    "        urllib.request.urlretrieve(dataURL, fileName)\n",
    "        print (\"End download, start to unzipn\")\n",
    "        with ZipFile(\"./\" + fileName, 'r') as zip:\n",
    "            zip.extractall(\"./data\")\n",
    "            zip.close()\n",
    "        print (\"End unzipped, data now useable under ./data\")\n",
    "    else:\n",
    "        print(\"Data folder already exists in:\", path +\"/data\", \" -> no new data loaded.\")\n",
    "except Exception as e:\n",
    "    print (\"Failed with Exception:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###--- Display Data---#\n",
    "\n",
    "images = glob.glob(os.path.join(\"./data/GTSRB/Training\", \"*/*.ppm\"), recursive=True)\n",
    "for i in range (0, 5):\n",
    "    print(\"Open random orignal Foro:\")\n",
    "    x = random.randint(0, len(images))\n",
    "    img = Image.open(images[x])\n",
    "    display(img)\n",
    "    print(\"Formatted Version\")\n",
    "    img = img.resize((200,200))\n",
    "    img = img.convert('LA')\n",
    "    display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###--- Create Dataset ---###\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self, dataset_folder, xDim, yDim, resize):\n",
    "        self.dataset_folder = dataset_folder\n",
    "        self.image_filenames = glob.glob(os.path.join(self.dataset_folder, \"*/*.ppm\"), recursive=True)\n",
    "        #xDim -> left to right\n",
    "        self.xDim = xDim\n",
    "        #yDim -> top to bottom\n",
    "        self.yDim = yDim\n",
    "        self.resize = resize\n",
    "        self.device = device\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "    \n",
    "    \n",
    "    # Returns the original image formatted, and formatted with blacked part\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.image_filenames[idx])\n",
    "        img = transforms.Resize((self.resize[0], self.resize[1]))(img)\n",
    "        img = transforms.functional.to_grayscale(img)\n",
    "        img = transforms.ToTensor()(img)\n",
    "        img_out = img.clone().detach()\n",
    "        img_out[:, self.xDim[0]:self.xDim[1], self.yDim[0]:self.yDim[1]] = 0\n",
    "        return img, img_out\n",
    "    \n",
    "\n",
    "# Creates dataset, parametrized is the blacked part, and the resize of the picture\n",
    "dataset=Dataset(dataset_folder=\"./data/GTSRB/Training\", xDim=[70, 100], yDim=[70, 100], resize=[200, 200])\n",
    "\n",
    "# Val_ratio chosen as in pytorch.org docu\n",
    "val_ratio = 0.2\n",
    "n_samples = len(dataset)\n",
    "shuffled_indices = np.random.permutation(n_samples)\n",
    "validationset_inds = shuffled_indices[:int(n_samples * val_ratio)]\n",
    "trainingset_inds = shuffled_indices[int(n_samples * val_ratio):]\n",
    "\n",
    "\n",
    "###--- Data Loader ---# \n",
    "batch_size = 8\n",
    "\n",
    "train_dataset = torch.utils.data.Subset(dataset, indices=trainingset_inds)\n",
    "val_dataset = torch.utils.data.Subset(dataset, indices=validationset_inds)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           num_workers=0,\n",
    "                                           shuffle=True, sampler=None,\n",
    "                                           collate_fn=None)\n",
    "\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           num_workers=0,\n",
    "                                           shuffle=False, sampler=None,\n",
    "                                           collate_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Idea for network structur:\n",
    "### Paper for best inpaiting: http://iizuka.cs.tsukuba.ac.jp/projects/completion/data/completion_sig2017.pdf\n",
    "### Source code for model, referenced to the paper: https://github.com/otenim/GLCIC-PyTorch\n",
    "\n",
    "class CompletionNetwork(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(CompletionNetwork, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, 4, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm2d(4)\n",
    "        self.act1 = nn.ReLU()\n",
    "       \n",
    "        self.conv2 = nn.Conv2d(4, 8, kernel_size=3, stride=2, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(8)\n",
    "        self.act2 = nn.ReLU()\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(8, 8, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(8)\n",
    "        self.act3 = nn.ReLU()\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(8, 8, kernel_size=3, stride=2, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(8)\n",
    "        self.act4 = nn.ReLU()\n",
    "       \n",
    "        self.conv5 = nn.Conv2d(8,8, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(8)\n",
    "        self.act5 = nn.ReLU()\n",
    "        \n",
    "        self.conv6 = nn.Conv2d(8, 8, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn6 = nn.BatchNorm2d(8)\n",
    "        self.act6 = nn.ReLU()\n",
    "        \n",
    "        self.deconv13 = nn.ConvTranspose2d(8, 8, kernel_size=4, stride=2, padding=1)\n",
    "        self.bn13 = nn.BatchNorm2d(8)\n",
    "        self.act13 = nn.ReLU()\n",
    "        \n",
    "        self.conv14 = nn.Conv2d(8, 8, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn14 = nn.BatchNorm2d(8)\n",
    "        self.act14 = nn.ReLU()\n",
    "        \n",
    "        self.deconv15 = nn.ConvTranspose2d(8, 4, kernel_size=4, stride=2, padding=1)\n",
    "        self.bn15 = nn.BatchNorm2d(4)\n",
    "        self.act15 = nn.ReLU()\n",
    "        \n",
    "        self.conv16 = nn.Conv2d(4, 2, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn16 = nn.BatchNorm2d(2)\n",
    "        self.act16 = nn.ReLU()\n",
    "        \n",
    "        self.conv17 = nn.Conv2d(2, 1, kernel_size=3, stride=1, padding=1)\n",
    "        self.act17 = nn.Sigmoid()\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.bn1(self.act1(self.conv1(x)))\n",
    "        x = self.bn2(self.act2(self.conv2(x)))\n",
    "        x = self.bn3(self.act3(self.conv3(x)))\n",
    "        x = self.bn4(self.act4(self.conv4(x)))\n",
    "        x = self.bn5(self.act5(self.conv5(x)))\n",
    "        x = self.bn6(self.act6(self.conv6(x)))\n",
    "        x = self.bn13(self.act13(self.deconv13(x)))\n",
    "        x = self.bn14(self.act14(self.conv14(x)))\n",
    "        x = self.bn15(self.act15(self.deconv15(x)))\n",
    "        x = self.bn16(self.act16(self.conv16(x)))\n",
    "        x = self.act17(self.conv17(x))\n",
    "        return x\n",
    "\n",
    "completionNetwork = CompletionNetwork(in_channels=1)\n",
    "completionNetwork.to(device)\n",
    "\n",
    "img, img_out = (iter(train_loader)).next()\n",
    "img = img[0].unsqueeze(0).to(device)\n",
    "\n",
    "completionNetwork(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CompletionNetwork(in_channels=1)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "total_loss = 0\n",
    "\n",
    "\n",
    "loss_function = nn.MSELoss(reduction='mean')\n",
    "\n",
    "class ModelTainer:\n",
    "    def __init__(self ,model, train_loader, val_loader, device, optimizer, loss_function, optimizer_args={}):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.device = device\n",
    "        self.optimizer_args = optimizer_args\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_function = loss_function\n",
    "        self.optimizer = optimizer\n",
    "                \n",
    "    def train_epoch(self, running_loss, epoch, n_epochs):\n",
    "        self.running_loss = running_loss \n",
    "        self.epoch = epoch\n",
    "        self.n_epochs = n_epochs\n",
    "        total_loss = 0\n",
    "        loop = tq.tqdm(enumerate(self.train_loader), total=len(self.train_loader), leave=False)\n",
    "        for i, data in loop:\n",
    "            img, target = data\n",
    "            img, target = img.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(img)\n",
    "            loss = loss_function(output, target)\n",
    "            \n",
    "            #total_loss += float(loss)\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loop.set_description(f\"Epoch [{self.epoch}/{self.n_epochs}] | Training\")\n",
    "            loop.set_postfix(loss =loss.item(), total_loss=total_loss)\n",
    "            \n",
    "            ###--- Tensorboard ---#\n",
    "            self.running_loss += loss.item()\n",
    "            if i % 100 == 99:\n",
    "                writer.add_scalar('training loss',\n",
    "                                self.running_loss / 1000,\n",
    "                                self.epoch * len(train_loader) + i)\n",
    "                self.running_loss = 0.0\n",
    "        \n",
    "                \n",
    "        return (total_loss) / len(train_loader), self.running_loss \n",
    "    \n",
    "    def evaluate(self, epoch, n_epochs):\n",
    "        self.epoch = epoch\n",
    "        self.n_epochs = n_epochs\n",
    "        total_loss = 0\n",
    "        correct = 0 \n",
    "        loop = tq.tqdm(enumerate(self.val_loader), total=len(self.val_loader), leave=False)\n",
    "        with torch.no_grad():\n",
    "            for i, data in loop:\n",
    "                img, target = data\n",
    "                img, target = img.to(device), target.to(device)\n",
    "                output = model(img)\n",
    "                predicted = torch.argmax(output.data, dim=1)\n",
    "                correct += (predicted == target).sum().item()\n",
    "                loss = loss_function(output, target)\n",
    "                total_loss += loss.item()\n",
    "                loop.set_description(f\"Epoch [{self.epoch}/{self.n_epochs}] | Validation\")\n",
    "                loop.set_postfix(loss =loss.item(), total_loss=total_loss)\n",
    "        return (total_loss) / len(val_loader), correct / (val_loader.batch_size * len(val_loader))\n",
    "    \n",
    "    def train(self, n_epochs):\n",
    "        print(f\"Model training starts: {datetime.now()} | working with: {device} | Amount of epochs: {n_epochs}\")\n",
    "        # Storing Results of Loss for plot\n",
    "        loss_values_trainingX = []\n",
    "        loss_values_trainingY = []\n",
    "        loss_values_evalutationX = []\n",
    "        loss_values_evalutationY = []\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        # Adjust learning rate\n",
    "        scheduler = StepLR(optimizer, step_size=2, gamma=0.1)\n",
    "\n",
    "        for e in range(1, n_epochs+1):\n",
    "            print(f\"Start epoch: {e} | Time: {datetime.now()}\")\n",
    "            start = datetime.now().replace(microsecond=0)\n",
    "            loss_train, running_loss = self.train_epoch(running_loss=running_loss, epoch=e, n_epochs=n_epochs)\n",
    "            loss_values_trainingX.append(e)\n",
    "            loss_values_trainingY.append(loss_train)\n",
    "            duration = datetime.now().replace(microsecond=0) - start\n",
    "            print(f\"Training epoch: {e} | Duration: {duration} | Loss: {loss_train}\")\n",
    "            start = datetime.now().replace(microsecond=0)\n",
    "            loss_eval, correct = self.evaluate(epoch=e, n_epochs=n_epochs)\n",
    "            loss_values_evalutationX.append(e)\n",
    "            loss_values_evalutationY.append(loss_eval)\n",
    "            duration = datetime.now().replace(microsecond=0) - start\n",
    "            print(f\"Validation epoch: {e} | Duration: {duration} | Loss: {loss_eval} | Correct: {correct}\")\n",
    "            print(f\"End epoch: {e} | Time: {datetime.now()}\")\n",
    "            scheduler.step()\n",
    "        \n",
    "        # Loss plotted\n",
    "        plt.plot(loss_values_trainingX, loss_values_trainingY, label = \"Training Loss\")\n",
    "        plt.plot(loss_values_evalutationX, loss_values_evalutationY, label = \"Validation Loss\")\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Plotting Loss for Train and Validation')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        print(f\"Model training end: {datetime.now()}\")\n",
    "    \n",
    "    def inference(self, loader=None):        \n",
    "        pass\n",
    "    \n",
    "trainer = ModelTainer(model=model, train_loader=train_loader, val_loader=val_loader, device=device, optimizer=optimizer, loss_function=loss_function)\n",
    "epochs = 15\n",
    "trainer.train(n_epochs=epochs)\n",
    "\n",
    "date = datetime.now().strftime(\"%Y%m%d_%H:%M:%S\")\n",
    "name = f\"MODEL_WATZELT_EPOCHS_{epochs}_DATE_{date}.pt\"\n",
    "\n",
    "###--- Save Model ---###\n",
    "torch.save(model.state_dict(), name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncomment if you want to use TensorBoard :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From time to time board is only visible in browser and does not show in the juypter notebooks (common bug known at stackoverflow)\n",
    "#%load_ext tensorboard\n",
    "# IF reload required\n",
    "# %reload_ext tensorboard\n",
    "# CARE If you want to use it, replace the path with the path of the log dirs, should be something like .../runs/write_x\n",
    "#%tensorboard --logdir PATH\n",
    "\n",
    "# Get access to tensorboard: http://localhost:6006/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model, uncomment for well working model\n",
    "print(f\"Working for model: {name}\")\n",
    "model = CompletionNetwork(in_channels=1)\n",
    "model.load_state_dict(torch.load(f\"{name}\"))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# helpfer function\n",
    "# https://www.pyimagesearch.com/2014/09/15/python-compare-two-images/\n",
    "def __mse__(imageA, imageB):\n",
    "    # the 'Mean Squared Error' between the two images is the\n",
    "    # sum of the squared difference between the two images;\n",
    "    # NOTE: the two images must have the same dimension\n",
    "    err = np.sum((imageA.astype(\"float\") - imageB.astype(\"float\")) ** 2)\n",
    "    err /= float(imageA.shape[0] * imageA.shape[1])\n",
    "    \n",
    "    # return the MSE, the lower the error, the more \"similar\"\n",
    "    # the two images are\n",
    "    return err\n",
    "\n",
    "mse_all = []\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(val_loader):\n",
    "        img, target = data\n",
    "        original, target = img.to(device), target.to(device)\n",
    "        prediction = model(target)\n",
    "        for i in range(0, len(img)):\n",
    "            original = img[i].squeeze(0).cpu().numpy()\n",
    "            _prediction = prediction[i].squeeze(0).cpu().numpy()\n",
    "            x = __mse__(original, _prediction)\n",
    "            mse_all.append(x)\n",
    "\n",
    "print(\"Average Mean Squared Error:\", mean(mse_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###--- Random Testing of Model ---###\n",
    "\n",
    "print(f\"Working for model: {name}\")\n",
    "model = CompletionNetwork(in_channels=1)\n",
    "model.load_state_dict(torch.load(f\"{name}\"))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Helper functions\n",
    "# Formats a random image from a path\n",
    "def __formatRandomPicture__(_img,  xDim, yDim, resize):\n",
    "    img = Image.open(_img)\n",
    "    img = transforms.Resize((resize[0], resize[1]))(img)\n",
    "    img = transforms.functional.to_grayscale(img)\n",
    "    img = transforms.ToTensor()(img)\n",
    "    img_out = img.clone().detach()\n",
    "    img_out[:, xDim[0]:xDim[1], yDim[0]:yDim[1]] = 0\n",
    "    return img, img_out\n",
    "\n",
    "# Plots the blacked, predicted and original picture\n",
    "def __plotter__(blacked, original, title='Overview'):\n",
    "    model_pred = model(blacked.unsqueeze(0).unsqueeze(0).to(device)).detach().cpu().clone().numpy().squeeze(0).squeeze(0)\n",
    "    \n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1,3)\n",
    "   \n",
    "    fig.suptitle(title, fontsize=14)\n",
    "    ax1.set_title('Blacked')\n",
    "    ax2.set_title('Orginal')\n",
    "    ax3.set_title('Model')\n",
    "\n",
    "    ax1.imshow(blacked, cmap=\"gray\")\n",
    "    ax2.imshow(original, cmap=\"gray\")\n",
    "    ax3.imshow(model_pred, cmap=\"gray\")\n",
    "    \n",
    "    plt.tight_layout()    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "data_iterator_train = iter(train_loader)\n",
    "imgs_train, targets_train = data_iterator_train.next() \n",
    "\n",
    "data_iterator_val = iter(val_loader)\n",
    "imgs_val, targets_val = data_iterator_val.next() \n",
    "for i in range (4, 7):\n",
    "    __plotter__(original = imgs_train[i].squeeze(0), blacked = targets_train[i].squeeze(0), title= \"Overview foto: training set\")\n",
    "    print()\n",
    "    __plotter__(original = imgs_val[i].squeeze(0), blacked = targets_val[i].squeeze(0), title= \"Overview foto: validation set\")\n",
    "    print()\n",
    "\n",
    "\n",
    "# Enter URL of jpg, png, ppm\n",
    "# Should have at least .xxx as file ending\n",
    "photoArray=[\"https://enter_picture_url_example.jpg\"]\n",
    "\n",
    "x = 0\n",
    "for i in photoArray:\n",
    "    urllib.request.urlretrieve(str(i), f\"{str(x)}.{i[-3:]}\")\n",
    "    img, img_out = __formatRandomPicture__(_img=f\"{str(x)}.{i[-3:]}\", xDim=[60, 100], yDim=[60, 100], resize=[256, 256])\n",
    "    original = img.squeeze(0)\n",
    "    blacked = img_out.squeeze(0)\n",
    "    __plotter__(original=original, blacked=blacked, title=f\"Over foto: {i}\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m56",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m56"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}